{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebff1aeb",
   "metadata": {},
   "source": [
    "# 中国癌症患者数据集生存分析：数据预处理\n",
    "\n",
    "本notebook专注于中国癌症患者数据集的数据预处理，为后续的Cox回归、Random Survival Forest与DeepSurv深度学习模型对比研究做准备。\n",
    "\n",
    "## 研究目标\n",
    "- 对癌症患者数据进行全面的数据清洗和特征工程\n",
    "- 准备统一的数据格式供三种生存分析模型使用\n",
    "- 探索数据特征，为模型设计提供依据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b5dc7f",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库和依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c26cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础数据处理库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 可视化库\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.sans-serif'] = ['Noto Sans CJK SC']  # 支持中文显示\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 日期处理\n",
    "from datetime import datetime, timedelta\n",
    "import dateutil.parser as parser\n",
    "\n",
    "# 生存分析库\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# 机器学习库\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 其他工具\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"所有库导入成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db989d",
   "metadata": {},
   "source": [
    "## 2. 数据加载与初步探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据路径\n",
    "data_dir = Path('../data')\n",
    "raw_data_dir = data_dir / 'raw'\n",
    "processed_data_dir = data_dir / 'processed'\n",
    "processed_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 加载数据集\n",
    "df = pd.read_csv(raw_data_dir / 'dataset.csv')\n",
    "\n",
    "# 读取数据描述\n",
    "with open(raw_data_dir / 'description.txt', 'r', encoding='utf-8') as f:\n",
    "    description = f.read()\n",
    "    \n",
    "print(\"数据集描述：\")\n",
    "print(description)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 数据基本信息\n",
    "print(f\"数据集形状: {df.shape}\")\n",
    "print(f\"列数: {df.shape[1]}\")\n",
    "print(f\"行数: {df.shape[0]}\")\n",
    "print(\"\\n列名:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看前几行数据\n",
    "print(\"数据前5行:\")\n",
    "display(df.head())\n",
    "\n",
    "# 数据类型信息\n",
    "print(\"\\n数据类型信息:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 基本统计信息\n",
    "print(\"\\n数值型变量统计信息:\")\n",
    "display(df.describe())\n",
    "\n",
    "# 分类变量信息\n",
    "categorical_cols = ['Gender', 'Province', 'Ethnicity', 'TumorType', 'CancerStage', \n",
    "                   'Metastasis', 'TreatmentType', 'SurvivalStatus', 'SmokingStatus', \n",
    "                   'AlcoholUse', 'GeneticMutation', 'Comorbidities']\n",
    "\n",
    "print(\"\\n分类变量唯一值统计:\")\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"{col}: {df[col].nunique()} 个唯一值\")\n",
    "        print(f\"   前10个值: {df[col].value_counts().head(10).index.tolist()}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082467a",
   "metadata": {},
   "source": [
    "## 3. 数据质量评估和缺失值分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab95116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值分析\n",
    "def analyze_missing_values(df):\n",
    "    \"\"\"分析缺失值情况\"\"\"\n",
    "    missing_stats = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Missing_Count': df.isnull().sum(),\n",
    "        'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "        'Data_Type': df.dtypes\n",
    "    })\n",
    "    \n",
    "    # 添加非标准缺失值（如'N/A', '', 'None'等）\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            non_standard_missing = df[col].isin(['N/A', '', 'None', 'null', 'NULL']).sum()\n",
    "            missing_stats.loc[missing_stats['Column'] == col, 'Non_Standard_Missing'] = non_standard_missing\n",
    "            missing_stats.loc[missing_stats['Column'] == col, 'Total_Missing'] = (\n",
    "                missing_stats.loc[missing_stats['Column'] == col, 'Missing_Count'].values[0] + non_standard_missing\n",
    "            )\n",
    "        else:\n",
    "            missing_stats.loc[missing_stats['Column'] == col, 'Non_Standard_Missing'] = 0\n",
    "            missing_stats.loc[missing_stats['Column'] == col, 'Total_Missing'] = missing_stats.loc[missing_stats['Column'] == col, 'Missing_Count'].values[0]\n",
    "    \n",
    "    missing_stats['Total_Missing_Percentage'] = (missing_stats['Total_Missing'] / len(df)) * 100\n",
    "    missing_stats = missing_stats.sort_values('Total_Missing_Percentage', ascending=False)\n",
    "    \n",
    "    return missing_stats\n",
    "\n",
    "missing_analysis = analyze_missing_values(df)\n",
    "print(\"缺失值分析结果:\")\n",
    "display(missing_analysis)\n",
    "\n",
    "# 可视化缺失值模式\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "plt.title('缺失值模式热图')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理非标准缺失值\n",
    "def clean_missing_values(df):\n",
    "    \"\"\"清理非标准缺失值\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 将非标准缺失值替换为NaN\n",
    "    non_standard_missing = ['N/A', '', 'None', 'null', 'NULL', ' ']\n",
    "    for col in df_clean.columns:\n",
    "        if df_clean[col].dtype == 'object':\n",
    "            df_clean[col] = df_clean[col].replace(non_standard_missing, np.nan)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "df_clean = clean_missing_values(df)\n",
    "\n",
    "# 重新分析清理后的缺失值\n",
    "print(\"清理后的缺失值统计:\")\n",
    "missing_clean = df_clean.isnull().sum().sort_values(ascending=False)\n",
    "missing_clean_pct = (missing_clean / len(df_clean)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing_Count': missing_clean,\n",
    "    'Missing_Percentage': missing_clean_pct\n",
    "})\n",
    "\n",
    "display(missing_summary[missing_summary['Missing_Count'] > 0])\n",
    "\n",
    "# 数据质量概览\n",
    "print(f\"\\n数据质量概览:\")\n",
    "print(f\"总样本数: {len(df_clean)}\")\n",
    "print(f\"有缺失值的列数: {(df_clean.isnull().any()).sum()}\")\n",
    "print(f\"完全没有缺失值的样本数: {df_clean.dropna().shape[0]}\")\n",
    "print(f\"完整度: {(df_clean.dropna().shape[0] / len(df_clean)) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11dc47c",
   "metadata": {},
   "source": [
    "## 4. 数据预处理和特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf037dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建工作副本\n",
    "df_processed = df_clean.copy()\n",
    "\n",
    "# 1. 处理日期字段\n",
    "print(\"处理日期字段...\")\n",
    "\n",
    "def parse_date_safe(date_str):\n",
    "    \"\"\"安全解析日期\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    try:\n",
    "        return parser.parse(str(date_str))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 转换日期字段\n",
    "df_processed['DiagnosisDate'] = df_processed['DiagnosisDate'].apply(parse_date_safe)\n",
    "df_processed['SurgeryDate'] = df_processed['SurgeryDate'].apply(parse_date_safe)\n",
    "\n",
    "# 2. 创建生存分析必需的变量\n",
    "print(\"创建生存分析变量...\")\n",
    "\n",
    "# 生存状态转换为事件指示器（1=死亡，0=存活/右删失）\n",
    "df_processed['Event'] = (df_processed['SurvivalStatus'] == 'Deceased').astype(int)\n",
    "\n",
    "# 生存时间（使用FollowUpMonths作为观察时间）\n",
    "df_processed['Duration'] = df_processed['FollowUpMonths']\n",
    "\n",
    "# 检查生存时间的有效性\n",
    "print(f\"生存时间统计:\")\n",
    "print(f\"最小值: {df_processed['Duration'].min()}\")\n",
    "print(f\"最大值: {df_processed['Duration'].max()}\")\n",
    "print(f\"平均值: {df_processed['Duration'].mean():.2f}\")\n",
    "print(f\"事件发生率: {df_processed['Event'].mean():.2%}\")\n",
    "\n",
    "# 3. 处理分类变量\n",
    "print(\"\\n处理分类变量...\")\n",
    "\n",
    "# 定义分类变量\n",
    "categorical_features = ['Gender', 'Province', 'Ethnicity', 'TumorType', 'CancerStage', \n",
    "                       'Metastasis', 'TreatmentType', 'SmokingStatus', 'AlcoholUse']\n",
    "\n",
    "# 处理缺失值和编码\n",
    "for col in categorical_features:\n",
    "    if col in df_processed.columns:\n",
    "        # 用众数填充缺失值\n",
    "        mode_value = df_processed[col].mode().iloc[0] if not df_processed[col].mode().empty else 'Unknown'\n",
    "        df_processed[col] = df_processed[col].fillna(mode_value)\n",
    "        print(f\"{col}: 填充缺失值 ({df_clean[col].isnull().sum()} 个) -> '{mode_value}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 处理数值变量\n",
    "print(\"\\n处理数值变量...\")\n",
    "\n",
    "# 数值变量列表\n",
    "numerical_features = ['Age', 'TumorSize', 'ChemotherapySessions', 'RadiationSessions']\n",
    "\n",
    "# 处理数值变量的缺失值\n",
    "for col in numerical_features:\n",
    "    if col in df_processed.columns:\n",
    "        missing_count = df_processed[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            # 用中位数填充缺失值\n",
    "            median_value = df_processed[col].median()\n",
    "            df_processed[col] = df_processed[col].fillna(median_value)\n",
    "            print(f\"{col}: 填充 {missing_count} 个缺失值 -> 中位数 {median_value}\")\n",
    "\n",
    "# 5. 特征工程\n",
    "print(\"\\n特征工程...\")\n",
    "\n",
    "# 年龄分组\n",
    "df_processed['AgeGroup'] = pd.cut(df_processed['Age'], \n",
    "                                 bins=[0, 30, 50, 70, 100], \n",
    "                                 labels=['Young', 'Middle', 'Senior', 'Elderly'])\n",
    "\n",
    "# 肿瘤大小分组\n",
    "df_processed['TumorSizeGroup'] = pd.cut(df_processed['TumorSize'],\n",
    "                                       bins=[0, 5, 10, 15, float('inf')],\n",
    "                                       labels=['Small', 'Medium', 'Large', 'VeryLarge'])\n",
    "\n",
    "# 治疗强度指标\n",
    "df_processed['TreatmentIntensity'] = (df_processed['ChemotherapySessions'] + \n",
    "                                     df_processed['RadiationSessions'])\n",
    "\n",
    "# 是否接受手术\n",
    "df_processed['HasSurgery'] = (~df_processed['SurgeryDate'].isna()).astype(int)\n",
    "\n",
    "# 是否有并发症\n",
    "df_processed['HasComorbidities'] = (~df_processed['Comorbidities'].isna()).astype(int)\n",
    "\n",
    "# 是否有基因突变\n",
    "df_processed['HasGeneticMutation'] = (~df_processed['GeneticMutation'].isna()).astype(int)\n",
    "\n",
    "print(\"特征工程完成！\")\n",
    "print(f\"新增特征: AgeGroup, TumorSizeGroup, TreatmentIntensity, HasSurgery, HasComorbidities, HasGeneticMutation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 编码分类变量\n",
    "print(\"编码分类变量...\")\n",
    "\n",
    "# 为生存分析准备编码后的数据\n",
    "df_encoded = df_processed.copy()\n",
    "\n",
    "# 使用Label Encoding处理有序分类变量\n",
    "ordinal_features = {\n",
    "    'CancerStage': ['I', 'II', 'III', 'IV'],\n",
    "    'AgeGroup': ['Young', 'Middle', 'Senior', 'Elderly'],\n",
    "    'TumorSizeGroup': ['Small', 'Medium', 'Large', 'VeryLarge']\n",
    "}\n",
    "\n",
    "label_encoders = {}\n",
    "for feature, order in ordinal_features.items():\n",
    "    if feature in df_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        # 确保编码顺序\n",
    "        df_encoded[feature] = df_encoded[feature].astype('category')\n",
    "        if feature == 'CancerStage':\n",
    "            df_encoded[feature] = df_encoded[feature].cat.reorder_categories(order, ordered=True)\n",
    "        elif feature in ['AgeGroup', 'TumorSizeGroup']:\n",
    "            df_encoded[feature] = df_encoded[feature].cat.reorder_categories(order, ordered=True)\n",
    "        \n",
    "        df_encoded[feature + '_encoded'] = le.fit_transform(df_encoded[feature])\n",
    "        label_encoders[feature] = le\n",
    "        print(f\"{feature} 编码映射: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "# 使用One-Hot Encoding处理无序分类变量\n",
    "nominal_features = ['Gender', 'Province', 'Ethnicity', 'TumorType', 'Metastasis', \n",
    "                   'TreatmentType', 'SmokingStatus', 'AlcoholUse']\n",
    "\n",
    "for feature in nominal_features:\n",
    "    if feature in df_encoded.columns:\n",
    "        # 获取哑变量\n",
    "        dummies = pd.get_dummies(df_encoded[feature], prefix=feature, drop_first=True)\n",
    "        df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "        print(f\"{feature}: 创建 {dummies.shape[1]} 个哑变量\")\n",
    "\n",
    "print(f\"\\n编码后数据形状: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103f5ee6",
   "metadata": {},
   "source": [
    "## 5. 探索性数据分析（EDA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 癌症类型分布\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 癌症类型分布\n",
    "tumor_counts = df_processed['TumorType'].value_counts()\n",
    "axes[0,0].pie(tumor_counts.values, labels=tumor_counts.index, autopct='%1.1f%%')\n",
    "axes[0,0].set_title('癌症类型分布')\n",
    "\n",
    "# 癌症分期分布\n",
    "stage_counts = df_processed['CancerStage'].value_counts()\n",
    "axes[0,1].bar(stage_counts.index, stage_counts.values)\n",
    "axes[0,1].set_title('癌症分期分布')\n",
    "axes[0,1].set_xlabel('癌症分期')\n",
    "axes[0,1].set_ylabel('患者数量')\n",
    "\n",
    "# 性别分布\n",
    "gender_counts = df_processed['Gender'].value_counts()\n",
    "axes[1,0].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%')\n",
    "axes[1,0].set_title('性别分布')\n",
    "\n",
    "# 生存状态分布\n",
    "survival_counts = df_processed['SurvivalStatus'].value_counts()\n",
    "axes[1,1].bar(survival_counts.index, survival_counts.values, color=['green', 'red'])\n",
    "axes[1,1].set_title('生存状态分布')\n",
    "axes[1,1].set_xlabel('生存状态')\n",
    "axes[1,1].set_ylabel('患者数量')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. 年龄和肿瘤大小分布\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 年龄分布\n",
    "axes[0].hist(df_processed['Age'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0].set_title('年龄分布')\n",
    "axes[0].set_xlabel('年龄')\n",
    "axes[0].set_ylabel('频数')\n",
    "\n",
    "# 肿瘤大小分布\n",
    "axes[1].hist(df_processed['TumorSize'].dropna(), bins=30, alpha=0.7, color='lightcoral')\n",
    "axes[1].set_title('肿瘤大小分布')\n",
    "axes[1].set_xlabel('肿瘤大小 (cm)')\n",
    "axes[1].set_ylabel('频数')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 地区分布分析\n",
    "plt.figure(figsize=(14, 8))\n",
    "province_counts = df_processed['Province'].value_counts().head(15)  # 显示前15个省份\n",
    "plt.bar(range(len(province_counts)), province_counts.values)\n",
    "plt.title('各省份患者分布 (前15名)')\n",
    "plt.xlabel('省份')\n",
    "plt.ylabel('患者数量')\n",
    "plt.xticks(range(len(province_counts)), province_counts.index, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. 生存时间与生存状态关系\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 生存时间分布（按生存状态分组）\n",
    "for status in df_processed['SurvivalStatus'].unique():\n",
    "    subset = df_processed[df_processed['SurvivalStatus'] == status]['Duration']\n",
    "    axes[0].hist(subset, alpha=0.6, label=status, bins=20)\n",
    "axes[0].set_title('生存时间分布（按生存状态）')\n",
    "axes[0].set_xlabel('跟进月份')\n",
    "axes[0].set_ylabel('频数')\n",
    "axes[0].legend()\n",
    "\n",
    "# 年龄与生存时间关系\n",
    "scatter = axes[1].scatter(df_processed['Age'], df_processed['Duration'], \n",
    "                         c=df_processed['Event'], alpha=0.6, cmap='RdYlBu')\n",
    "axes[1].set_title('年龄与生存时间关系')\n",
    "axes[1].set_xlabel('年龄')\n",
    "axes[1].set_ylabel('跟进月份')\n",
    "plt.colorbar(scatter, ax=axes[1], label='事件发生(1=死亡, 0=存活)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. 治疗类型与生存状态关系\n",
    "treatment_survival = pd.crosstab(df_processed['TreatmentType'], df_processed['SurvivalStatus'])\n",
    "treatment_survival_pct = pd.crosstab(df_processed['TreatmentType'], df_processed['SurvivalStatus'], normalize='index') * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# 绝对数量\n",
    "treatment_survival.plot(kind='bar', ax=axes[0], color=['green', 'red'])\n",
    "axes[0].set_title('治疗类型与生存状态（绝对数量）')\n",
    "axes[0].set_xlabel('治疗类型')\n",
    "axes[0].set_ylabel('患者数量')\n",
    "axes[0].legend(title='生存状态')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 百分比\n",
    "treatment_survival_pct.plot(kind='bar', ax=axes[1], color=['green', 'red'])\n",
    "axes[1].set_title('治疗类型与生存状态（百分比）')\n",
    "axes[1].set_xlabel('治疗类型')\n",
    "axes[1].set_ylabel('百分比')\n",
    "axes[1].legend(title='生存状态')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb373c74",
   "metadata": {},
   "source": [
    "## 6. 生存分析数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53033ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 创建最终的建模数据集\n",
    "print(\"准备建模数据集...\")\n",
    "\n",
    "# 选择用于建模的特征\n",
    "feature_columns = [\n",
    "    # 基础特征\n",
    "    'Age', 'TumorSize', 'ChemotherapySessions', 'RadiationSessions',\n",
    "    'TreatmentIntensity', 'HasSurgery', 'HasComorbidities', 'HasGeneticMutation',\n",
    "    \n",
    "    # 编码后的有序特征\n",
    "    'CancerStage_encoded', 'AgeGroup_encoded', 'TumorSizeGroup_encoded'\n",
    "]\n",
    "\n",
    "# 添加所有的哑变量\n",
    "dummy_columns = [col for col in df_encoded.columns if any(prefix in col for prefix in \n",
    "                ['Gender_', 'Province_', 'Ethnicity_', 'TumorType_', 'Metastasis_', \n",
    "                 'TreatmentType_', 'SmokingStatus_', 'AlcoholUse_'])]\n",
    "\n",
    "feature_columns.extend(dummy_columns)\n",
    "\n",
    "# 生存分析目标变量\n",
    "target_columns = ['Duration', 'Event']\n",
    "\n",
    "# 检查特征是否存在\n",
    "available_features = [col for col in feature_columns if col in df_encoded.columns]\n",
    "missing_features = [col for col in feature_columns if col not in df_encoded.columns]\n",
    "\n",
    "print(f\"可用特征数量: {len(available_features)}\")\n",
    "print(f\"缺失特征: {missing_features}\")\n",
    "\n",
    "# 创建建模数据集\n",
    "modeling_data = df_encoded[available_features + target_columns + ['PatientID']].copy()\n",
    "\n",
    "# 移除任何仍有缺失值的行\n",
    "print(f\"处理前数据形状: {modeling_data.shape}\")\n",
    "modeling_data = modeling_data.dropna()\n",
    "print(f\"处理后数据形状: {modeling_data.shape}\")\n",
    "\n",
    "# 2. 数据质量检查\n",
    "print(f\"\\n数据质量检查:\")\n",
    "print(f\"生存时间范围: {modeling_data['Duration'].min()} - {modeling_data['Duration'].max()}\")\n",
    "print(f\"事件发生率: {modeling_data['Event'].mean():.2%}\")\n",
    "print(f\"平均随访时间: {modeling_data['Duration'].mean():.1f} 月\")\n",
    "\n",
    "# 3. 特征统计\n",
    "X = modeling_data[available_features]\n",
    "y_duration = modeling_data['Duration']\n",
    "y_event = modeling_data['Event']\n",
    "\n",
    "print(f\"\\n特征矩阵形状: {X.shape}\")\n",
    "print(f\"特征数量: {len(available_features)}\")\n",
    "print(f\"样本数量: {len(modeling_data)}\")\n",
    "\n",
    "# 显示特征列表\n",
    "print(f\"\\n建模特征列表:\")\n",
    "for i, feature in enumerate(available_features, 1):\n",
    "    print(f\"{i:2d}. {feature}\")\n",
    "    if i % 5 == 0:  # 每5个特征换行\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 数据标准化（为深度学习模型准备）\n",
    "print(\"数据标准化...\")\n",
    "\n",
    "# 分离数值特征和分类特征\n",
    "numerical_cols = ['Age', 'TumorSize', 'ChemotherapySessions', 'RadiationSessions', 'TreatmentIntensity']\n",
    "categorical_cols = [col for col in available_features if col not in numerical_cols]\n",
    "\n",
    "print(f\"数值特征: {len(numerical_cols)} 个\")\n",
    "print(f\"分类特征: {len(categorical_cols)} 个\")\n",
    "\n",
    "# 标准化数值特征\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "print(\"数值特征标准化完成\")\n",
    "\n",
    "# 5. 数据分割\n",
    "print(\"\\n数据集分割...\")\n",
    "\n",
    "# 分层抽样，确保训练集和测试集的事件率相似\n",
    "X_train, X_test, y_train_duration, y_test_duration, y_train_event, y_test_event = train_test_split(\n",
    "    X_scaled, y_duration, y_event, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_event\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape[0]}\")\n",
    "print(f\"测试集大小: {X_test.shape[0]}\")\n",
    "print(f\"训练集事件率: {y_train_event.mean():.2%}\")\n",
    "print(f\"测试集事件率: {y_test_event.mean():.2%}\")\n",
    "\n",
    "# 6. 保存预处理器和编码器\n",
    "print(\"\\n保存预处理器...\")\n",
    "\n",
    "preprocessors = {\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': label_encoders,\n",
    "    'feature_columns': available_features,\n",
    "    'numerical_cols': numerical_cols,\n",
    "    'categorical_cols': categorical_cols\n",
    "}\n",
    "\n",
    "# 保存到文件\n",
    "with open(processed_data_dir / 'preprocessors.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessors, f)\n",
    "\n",
    "print(\"预处理器保存完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45258e05",
   "metadata": {},
   "source": [
    "## 7. 保存处理后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9656c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 保存原始清理后的数据\n",
    "df_processed.to_csv(processed_data_dir / 'cleaned_data.csv', index=False)\n",
    "print(\"清理后的原始数据已保存: cleaned_data.csv\")\n",
    "\n",
    "# 2. 保存编码后的完整数据\n",
    "df_encoded.to_csv(processed_data_dir / 'encoded_data.csv', index=False)\n",
    "print(\"编码后的完整数据已保存: encoded_data.csv\")\n",
    "\n",
    "# 3. 保存建模数据集\n",
    "modeling_data.to_csv(processed_data_dir / 'modeling_data.csv', index=False)\n",
    "print(\"建模数据集已保存: modeling_data.csv\")\n",
    "\n",
    "# 4. 保存分割后的训练和测试数据\n",
    "train_data = pd.concat([\n",
    "    X_train, \n",
    "    pd.DataFrame({'Duration': y_train_duration, 'Event': y_train_event}, index=X_train.index)\n",
    "], axis=1)\n",
    "\n",
    "test_data = pd.concat([\n",
    "    X_test, \n",
    "    pd.DataFrame({'Duration': y_test_duration, 'Event': y_test_event}, index=X_test.index)\n",
    "], axis=1)\n",
    "\n",
    "train_data.to_csv(processed_data_dir / 'train_data.csv', index=False)\n",
    "test_data.to_csv(processed_data_dir / 'test_data.csv', index=False)\n",
    "\n",
    "print(\"训练数据已保存: train_data.csv\")\n",
    "print(\"测试数据已保存: test_data.csv\")\n",
    "\n",
    "# 5. 保存数据摘要报告\n",
    "summary_report = {\n",
    "    'original_shape': df.shape,\n",
    "    'processed_shape': modeling_data.shape,\n",
    "    'feature_count': len(available_features),\n",
    "    'sample_count': len(modeling_data),\n",
    "    'event_rate': modeling_data['Event'].mean(),\n",
    "    'mean_followup': modeling_data['Duration'].mean(),\n",
    "    'train_size': len(train_data),\n",
    "    'test_size': len(test_data),\n",
    "    'features': available_features\n",
    "}\n",
    "\n",
    "with open(processed_data_dir / 'data_summary.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"数据预处理摘要报告\\n\")\n",
    "    f.write(\"=\" * 30 + \"\\n\\n\")\n",
    "    f.write(f\"原始数据形状: {summary_report['original_shape']}\\n\")\n",
    "    f.write(f\"处理后数据形状: {summary_report['processed_shape']}\\n\")\n",
    "    f.write(f\"特征数量: {summary_report['feature_count']}\\n\")\n",
    "    f.write(f\"样本数量: {summary_report['sample_count']}\\n\")\n",
    "    f.write(f\"事件发生率: {summary_report['event_rate']:.2%}\\n\")\n",
    "    f.write(f\"平均随访时间: {summary_report['mean_followup']:.1f} 月\\n\")\n",
    "    f.write(f\"训练集大小: {summary_report['train_size']}\\n\")\n",
    "    f.write(f\"测试集大小: {summary_report['test_size']}\\n\\n\")\n",
    "    f.write(\"特征列表:\\n\")\n",
    "    for i, feature in enumerate(summary_report['features'], 1):\n",
    "        f.write(f\"{i:2d}. {feature}\\n\")\n",
    "\n",
    "print(\"数据摘要报告已保存: data_summary.txt\")\n",
    "\n",
    "print(f\"\\n数据预处理完成！\")\n",
    "print(f\"所有文件已保存到: {processed_data_dir}\")\n",
    "print(f\"共生成 {len(list(processed_data_dir.glob('*')))} 个文件\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
